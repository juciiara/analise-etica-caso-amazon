# 🌐 Experiência Prática – Ética, Cidadania Digital e Direitos

## 1️⃣ Escolha do Caso  
O sistema de recrutamento da **Amazon** utilizava inteligência artificial para automatizar a triagem de currículos. No entanto, acabou sendo descontinuado por **favorecer candidatos homens** e **prejudicar mulheres**, revelando um profundo **viés algorítmico**.  

Este caso mostra que tecnologias avançadas podem **reproduzir desigualdades sociais**, mesmo quando a intenção é agilizar processos.

---

## 2️⃣ Análise Ética Estruturada  

### ⚖️ 2.1 Viés e Justiça  
- **Dados históricos refletem preconceitos culturais e institucionais**.  
- A IA **replicou padrões discriminatórios**, rejeitando currículos femininos com qualificações equivalentes às masculinas.  
- **Justiça algorítmica não é automática**: sem supervisão, sistemas de IA podem reforçar desigualdades existentes.

### 🔍 2.2 Transparência e Explicabilidade  
- Funcionava como uma **“caixa-preta”**, sem explicações claras para rejeições.  
- Isso dificultou que candidatos e gestores **entendessem ou contestassem decisões**, criando uma lacuna de confiança.  
- Sistemas que impactam carreiras exigem **transparência ativa**, com critérios claros e auditáveis.

### 🌍 2.3 Impacto Social e Direitos  
- Excluiu estruturalmente mulheres no mercado de tecnologia.  
- Falta de transparência sobre dados pessoais levanta questões legais (**LGPD**).  
- Demonstra que **responsabilidade social e conformidade legal** estão interligadas.

### 🛡️ 2.4 Responsabilidade e Governança  
- Destaca a necessidade de **supervisão ética contínua**.  
- Medidas que poderiam ter evitado o problema:  
  - Revisão e diversificação da base de dados;  
  - Monitoramento constante do algoritmo;  
  - Inclusão de especialistas em ética e diversidade no desenvolvimento.

📌 **Aprendizado central**: IA sem governança ética é risco social. **Decisões automatizadas não eliminam a responsabilidade humana**.

---

## 3️⃣ Posicionamento Final  
A descontinuação do sistema foi necessária, mas o mais importante é transformar o caso em **aprendizado**.  

Futuras soluções de IA devem ser planejadas com **ética desde o início**, garantindo que a tecnologia **corrija desigualdades, e não as reproduza**.

---

## 4️⃣ Recomendações Práticas  
1. Implementar **auditorias contínuas de viés** e avaliações de impacto social.  
2. Garantir **transparência e explicabilidade**, fornecendo detalhes sobre decisões automatizadas.  
3. Formar **comitês multidisciplinares** (tecnologia, ética e diversidade) para supervisão.  
4. Utilizar **bases de dados representativas**, evitando estereótipos históricos.  
5. Desenvolver programas de **conscientização e treinamento em ética em IA**.

---

## 5️⃣ Equipe  
- **Leandro Cavalcante**  
- **Ana Paula Bastos**  
- **Suzana Marks**  
- **Juciara E. Conceição**  

---

📄 [Visualizar PDF completo do relatório](https://github.com/leandrotottioficialcantor-cpu/Educa_livre/blob/main/docs/Relatorio_Etica_Amazon.pdf)  

